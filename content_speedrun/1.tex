\documentclass[11pt,a4paper]{article}

% ---------- Preamble: layout & typography ----------
\usepackage[margin=1in]{geometry}
\usepackage{microtype}
\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage{lmodern}
\usepackage[dvipsnames]{xcolor}
\usepackage{amsmath,amssymb}
\usepackage{enumitem}
\usepackage{tabularx,booktabs}
\usepackage{graphicx}
\usepackage{hyperref}
% Sanitize bookmark/ToC strings (avoid color/math in PDF strings)
\pdfstringdefDisableCommands{%%
  \def\color#1{}%%
  \def\textbf#1{#1}%%
  \def\emph#1{#1}%%
  \def\textrightarrow{}%%
}
\hypersetup{
  colorlinks=true,
  linkcolor=MidnightBlue,
  urlcolor=MidnightBlue,
  citecolor=MidnightBlue
}
\usepackage{fancyhdr}
\usepackage{titlesec}
\usepackage{parskip}
\usepackage{tcolorbox}
\tcbuselibrary{skins,breakable}
\usepackage{listings}
\usepackage{pifont}

% ---------- Colors ----------
\definecolor{Accent}{HTML}{0F766E}      % teal-ish for headers
\definecolor{SoftBg}{HTML}{F3F7F7}      % light background for boxes
\definecolor{RecallBg}{HTML}{FFF6E5}    % soft amber for recall
\definecolor{PracticeBg}{HTML}{EEF6FF}  % soft blue for practice
\definecolor{Rbg}{HTML}{F6F6F6}         % code bg

% ---------- Headings ----------
\titleformat{\section}
  {\Large\bfseries\color{Accent}}{Lecture \thesection}{0.6em}{}
\titleformat{\subsection}
  {\bfseries}{\thesubsection}{0.6em}{}


% ---------- Header / Footer ----------
\pagestyle{fancy}
\fancyhf{}
\lhead{STAT115 Content Speed-Run}
\rhead{\thepage}
\renewcommand{\headrulewidth}{0.4pt}

% ---------- Lists ----------
\setlist[itemize]{topsep=4pt,itemsep=2pt,parsep=0pt,leftmargin=1.2em}
\setlist[enumerate]{topsep=4pt,itemsep=3pt,parsep=0pt,leftmargin=1.4em}

% ---------- Listings (R) ----------
\lstdefinelanguage{R}{
  morekeywords={if,else,repeat,while,function,for,in,next,break,TRUE,FALSE,NA,NaN,Inf},
  sensitive=true,
  morecomment=[l]{\#},
  morestring=[b]"
}
\lstset{
  basicstyle=\ttfamily\small,
  keywordstyle=\bfseries,
  commentstyle=\itshape\color{gray!70!black},
  showstringspaces=false,
  frame=single,
  framerule=0pt,
  rulecolor=\color{white},
  backgroundcolor=\color{Rbg},
  columns=fullflexible,
  keepspaces=true,
  xleftmargin=0.5em,
  xrightmargin=0.5em
}

% ---------- Pedagogy-flavoured boxes ----------
\newtcolorbox{corebox}{
  breakable, enhanced, colback=SoftBg, colframe=Accent!40!black,
  title=\textbf{Core Content} \hfill \scriptsize(2--6 min skim),
  boxrule=0.5pt, arc=2mm, left=2mm, right=2mm, top=1mm, bottom=1mm
}

\newtcolorbox{recallbox}{
  breakable, enhanced, colback=RecallBg, colframe=orange!60!black,
  title=\textbf{Active Recall} \hfill \scriptsize(cover \emph{Core Content} above; answer from memory),
  boxrule=0.5pt, arc=2mm, left=2mm, right=2mm, top=1mm, bottom=1mm
}

\newtcolorbox{practicebox}{
  breakable, enhanced, colback=PracticeBg, colframe=blue!60!black,
  title=\textbf{Micro Practice} \hfill \scriptsize(5--10 min),
  boxrule=0.5pt, arc=2mm, left=2mm, right=2mm, top=1mm, bottom=1mm
}

\newtcolorbox{rbox}{
  breakable, enhanced, colback=Rbg, colframe=black!15,
  title=\textbf{R Mini-Kit} \hfill \scriptsize(copy \& run),
  boxrule=0.5pt, arc=2mm, left=2mm, right=2mm, top=1mm, bottom=1mm
}

\newcommand{\reviewticks}{
  \vspace{0.4em}
  \noindent\scriptsize\textbf{Spaced Review:}
  \fbox{\phantom{D0}} Day 0\quad
  \fbox{\phantom{D2}} Day 2\quad
  \fbox{\phantom{D7}} Day 7\quad
  \fbox{\phantom{D14}} Day 14
}

% ---------- Title ----------
\title{\vspace{-1.5em}\textbf{STAT115 Content Speed-Run}\\
\large Self-Study Pack (Active Recall + Micro Practice + R Mini-Kit)}
\author{Prepared for catch-up after a six-week absence}
\date{}

\begin{document}
\maketitle

\begin{tcolorbox}[colback=SoftBg,colframe=Accent!40!black,breakable,boxrule=0.5pt,arc=2mm,title=\textbf{How to use this pack (learning-science built-in)}]
\begin{itemize}
  \item \textbf{Active recall first, reread last:} answer from memory before checking. Speaking your answer out loud improves retention.
  \item \textbf{Dual coding:} sketch tiny diagrams (axes, curves, residual plots) alongside formulas and code.
  \item \textbf{Spacing \& interleaving:} tick the review boxes (Day 0/2/7/14) and mix topics during review.
  \item \textbf{Error log:} when you miss a recall item, write why and how you will avoid it next time.
\end{itemize}
\end{tcolorbox}

\tableofcontents
\newpage

% =========================================================
\section{Orientation \& What Statistics Is}

\begin{corebox}
\begin{itemize}
  \item Statistics is \textbf{learning from data} and about \textbf{describing and quantifying variability}.
  \item Tutorials are highly recommended; R is available on lab machines.
  \item Final exam: \textbf{3 hours}, about \textbf{90 multiple-choice} questions. Final grade: \(F = 0.7\times Exam + 0.3\times Assignments\).
\end{itemize}
\end{corebox}

\begin{recallbox}
\begin{enumerate}
  \item Complete: ``Statistics is \underline{\hspace{4cm}}.''
  \item Besides learning from data, what two words describe the focus of statistics?
  \item What is the final-exam format and duration?
  \item How is the final mark calculated?
  \item One reason tutorials add value?
\end{enumerate}
\end{recallbox}

\begin{practicebox}
Find two tutorial slots you can attend and write them here. Commit on paper as well.
\end{practicebox}

\begin{rbox}
No code yetâ€”just ensure you can open RStudio and run: \texttt{1 + 1}.
\end{rbox}

\reviewticks

% =========================================================
\section{Statistical Software (R focus)}

\begin{corebox}
\begin{itemize}
  \item We will use \textbf{R} via RStudio. Excel is common but limited for robust statistical analysis.
  \item Minimal R toolkit suffices: read data, summarise, tabulate, test, model, diagnose.
\end{itemize}
\end{corebox}

\begin{recallbox}
\begin{enumerate}
  \item Why is R preferred over pure spreadsheets for analysis?
  \item What does RStudio add on top of base R?
  \item Name two other statistical packages you know.
\end{enumerate}
\end{recallbox}

\begin{practicebox}
Create a new R script. Type the commands below and run them without errors.
\end{practicebox}

\begin{rbox}
\begin{lstlisting}[language=R]
# Reading and peeking at data
D <- read.csv("yourfile.csv")
head(D); summary(D)

# Categorical tabulation
T <- table(D$A, D$B); T
prop.table(T)      # overall proportions
prop.table(T, 1)   # row proportions
prop.table(T, 2)   # column proportions
\end{lstlisting}
\end{rbox}

\reviewticks

% =========================================================
\section{Contingency Tables \& Basic Probability}

\begin{corebox}
\begin{itemize}
  \item Contingency tables show \textbf{counts} and \textbf{proportions}; treat proportions as probabilities for practice.
  \item \textbf{Marginal} probabilities are in the margins; \textbf{joint} inside cells; \textbf{conditional} restrict to a row/column.
  \item Independence fails if \( \Pr(Survival \mid Sex) \ne \Pr(Survival) \).
\end{itemize}
\end{corebox}

\begin{recallbox}
\begin{enumerate}
  \item Where do marginal probabilities live?
  \item If total \(= 2092\) and female-survivors \(= 316\), compute \( \Pr(\text{female} \land \text{survived}) \).
  \item Explain in words why survival and sex are not independent in Titanic data.
  \item How do you convert a count table to proportions?
  \item Define ``joint'' vs ``conditional'' probability in one sentence each.
\end{enumerate}
\end{recallbox}

\begin{practicebox}
Using Titanic counts, calculate \( \Pr(S), \Pr(M), \Pr(S \land M), \Pr(S\mid M)\), then check independence.
\end{practicebox}

\begin{rbox}
\begin{lstlisting}[language=R]
# titanic: 2x2 table of counts, rows=sex, cols=survival
Total <- sum(titanic)
P <- titanic / Total; P
# Marginals
Pr_S <- margin.table(P, 2)["yes"]
Pr_M <- margin.table(P, 1)["male"]
# Conditional
Pr_S_given_M <- P["male","yes"] / Pr_M
\end{lstlisting}
\end{rbox}

\reviewticks

% =========================================================
\section{Populations, Parameters, Normal Model (First Look)}

\begin{corebox}
\begin{itemize}
  \item \textbf{Population vs sample}; \textbf{parameter} (\(\mu,\sigma\)) vs \textbf{statistic} (\(\bar{y}, s\)).
  \item Estimation targets parameters; the \textbf{Normal} distribution often models quantitative data.
\end{itemize}
\end{corebox}

\begin{recallbox}
\begin{enumerate}
  \item Give one parameter and its sample-statistic counterpart.
  \item Why introduce a distributional model like the Normal?
  \item What do \(\bar{y}\) and \(s\) estimate?
\end{enumerate}
\end{recallbox}

\begin{practicebox}
Sketch a bell curve; mark \(\mu\) and \(\pm 2\sigma\). Write what ``about 95\%'' means under Normal.
\end{practicebox}

\begin{rbox}
\begin{lstlisting}[language=R]
x <- rnorm(100, mean=0, sd=1)
mean(x); sd(x)
hist(x)  # quick visual
\end{lstlisting}
\end{rbox}

\reviewticks

% =========================================================
\section{Confidence Intervals (CIs), Confidence Level, SE, Sample Size}

\begin{corebox}
\begin{itemize}
  \item \texttt{t.test()} yields CIs for a mean; increasing \texttt{conf.level} widens the CI.
  \item Standard error of \(\bar{y}\): \( s/\sqrt{n} \). Larger \(s\) widens; larger \(n\) narrows (all else fixed).
  \item Design question: choose \(n\) to hit a target margin of error (MOE).
\end{itemize}
\end{corebox}

\begin{recallbox}
\begin{enumerate}
  \item How does raising \texttt{conf.level} affect CI width?
  \item Write SE\((\bar{y})\).
  \item Two levers to narrow a CI?
  \item Plain-English meaning of a 95\% CI?
  \item Why is it unethical to overstate \(n\)?
\end{enumerate}
\end{recallbox}

\begin{practicebox}
Run \texttt{t.test(GAG\$conc, conf.level = 0.90/0.95/0.99)}. Which is widest? Why?
\end{practicebox}

\begin{rbox}
\begin{lstlisting}[language=R]
out95 <- t.test(GAG$conc, conf.level = 0.95)
out99 <- t.test(GAG$conc, conf.level = 0.99)
out90 <- t.test(GAG$conc, conf.level = 0.90)
# Sample-size sketch for MOE (xi) using a pilot s
z <- qnorm(1-0.05/2); s <- sd(GAG$conc); xi <- 0.04
n_needed <- ceiling((z*s/xi)^2)
\end{lstlisting}
\end{rbox}

\reviewticks

% =========================================================
\section{Two Independent Means (Welch Two-Sample t)}

\begin{corebox}
\begin{itemize}
  \item Use \texttt{t.test(x, y)} for \textbf{independent groups} (Welch by default): outputs \(t, df, p\), CI, and group means.
  \item Interpretation: \(p\)-value measures \textbf{incompatibility with \(H_0\)}; \textbf{CI} indicates plausible effect size.
  \item With small samples, normality matters more; be cautious.
\end{itemize}
\end{corebox}

\begin{recallbox}
\begin{enumerate}
  \item State \(H_0\) and \(H_A\) for comparing two means.
  \item What does Welch guard against vs pooled-variance \(t\)?
  \item Why doesnâ€™t the \(p\)-value tell ``how big'' the effect is?
  \item Which parameter does the CI estimate here (write \(\mu_1 - \mu_2\))?
  \item One assumption to check in each group?
\end{enumerate}
\end{recallbox}

\begin{practicebox}
Given \texttt{control\$Freq} and \texttt{solitary\$Freq}, run \texttt{t.test(control\$Freq, solitary\$Freq)} and interpret:
Is 0 inside the CI? Which group mean is higher and by how much (roughly)?
\end{practicebox}

\begin{rbox}
\begin{lstlisting}[language=R]
out <- t.test(control$Freq, solitary$Freq)
out$estimate     # group means (mind the order)
out$conf.int     # CI for mu_control - mu_solitary
out$p.value
\end{lstlisting}
\end{rbox}

\reviewticks

% =========================================================
\section{Paired Data (Within-Subject)}

\begin{corebox}
\begin{itemize}
  \item Paired design: each observation in A corresponds to one in B; analyze \textbf{differences}.
  \item Two equivalent paths: (1) compute differences and one-sample \(t\); (2) \texttt{t.test(A,B, paired=TRUE)}.
  \item The CI from both approaches is \textbf{identical}; wording differs.
\end{itemize}
\end{corebox}

\begin{recallbox}
\begin{enumerate}
  \item Why analyze paired data via differences?
  \item What parameter is tested in paired \(t\) (write \(\mu_d\))?
  \item How do the two outputs differ in wording but not numbers?
  \item Give a real-world example that should be analyzed as paired.
  \item What goes wrong if you treat paired observations as independent?
\end{enumerate}
\end{recallbox}

\begin{practicebox}
For auditory/visual reaction times, create a difference variable and run both analyses. Confirm the same CI.
\end{practicebox}

\begin{rbox}
\begin{lstlisting}[language=R]
AV <- read.csv("AV.csv")
AV$differ <- AV$visual - AV$auditory
# Option 1
one <- t.test(AV$differ)
# Option 2 (equivalent CI)
two <- t.test(AV$visual, AV$auditory, paired=TRUE)
one$conf.int; two$conf.int
\end{lstlisting}
\end{rbox}

\reviewticks

% =========================================================
\section{Simple Linear Regression (fit -> diagnose)}

\begin{corebox}
\begin{itemize}
  \item Model: \( y = \beta_0 + \beta_1 x + \varepsilon \). Fitted by least squares (minimise squared residuals).
  \item Interpret \(\beta_1\) as expected change in \(y\) per 1-unit increase in \(x\) (when sensible).
  \item Be cautious interpreting \(\beta_0\) if \(x=0\) lies outside observed range.
\end{itemize}
\end{corebox}

\begin{recallbox}
\begin{enumerate}
  \item In words, what are fitted values and residuals?
  \item Explain \(\beta_1\) in your own words.
  \item Why might \(\beta_0\) be uninterpretable in some data sets?
\end{enumerate}
\end{recallbox}

\begin{practicebox}
Fit a line predicting possum head length from total length. Write one sentence interpreting \(\beta_1\).
\end{practicebox}

\begin{rbox}
\begin{lstlisting}[language=R]
m <- lm(head_l ~ total_l, data=possum)
coef(m); fitted(m); residuals(m)
\end{lstlisting}
\end{rbox}

\reviewticks

% =========================================================
% =========================================================
\section{Checking SLR Assumptions (LINE) with Residuals}

\begin{corebox}
\begin{itemize}
  \item Assumptions: \textbf{LINE} = Linearity, Independence, Normality, Equal variance of errors.
  \item Use \textbf{studentised residuals} and \textbf{residuals vs fitted} to diagnose trend (linearity), funnel (variance), outliers.
\end{itemize}
\end{corebox}

\begin{recallbox}
\begin{enumerate}
  \item Expand LINE.
  \item Which plot do you look at first to check assumptions?
  \item High-level meaning of a studentised residual?
  \item Name one worrying pattern in residuals-vs-fitted.
  \item Why check assumptions after fitting?
\end{enumerate}
\end{recallbox}

\begin{practicebox}
Make the residual plot for the possum model; add a horizontal line at 0. Note any trends or funnels.
\end{practicebox}

\begin{rbox}
\begin{lstlisting}[language=R]
fit <- lm(head_l ~ total_l, data=possum)
rvf <- rstudent(fit)
plot(fitted(fit), rvf); abline(h=0)
\end{lstlisting}
\end{rbox}

\reviewticks

% =========================================================
\section{Sampling Distributions and Central Limit Theorem (CLT)}

\begin{corebox}
\begin{itemize}
  \item A sampling distribution is the distribution of a statistic (for example, \(\bar y\)) under repeated sampling.
  \item CLT (informal): for large \(n\), the sampling distribution of \(\bar y\) is approximately Normal with mean \(\mu\) and SE \(s/\sqrt{n}\), regardless of the population shape (mild conditions).
  \item Standard error connects sample size and variability: larger \(n\) leads to smaller SE and tighter CIs.
\end{itemize}
\end{corebox}

\begin{recallbox}
\begin{enumerate}
  \item Define sampling distribution in one sentence.
  \item State the CLT informally for the sample mean.
  \item How does SE(\(\bar y\)) scale with \(n\)?
\end{enumerate}
\end{recallbox}

\begin{practicebox}
Simulate 2000 sample means from a skewed distribution (for example, Exponential). Make a histogram and compare with a Normal curve.
\end{practicebox}

\begin{rbox}
\begin{lstlisting}[language=R]
set.seed(1)
means <- replicate(2000, mean(rexp(50, rate = 1)))
hist(means, breaks = 30, main = "Sampling distribution of ybar")
mean(means); sd(means)
\end{lstlisting}
\end{rbox}

\reviewticks

% =========================================================
\section{Proportions and the Binomial Model}

\begin{corebox}
\begin{itemize}
  \item Binary outcomes (success or failure) can be modelled with Binomial(\(n, p\)).
  \item Sample proportion \(\hat p = X/n\) estimates \(p\); \(\operatorname{SE}(\hat p) \approx \sqrt{\hat p(1-\hat p)/n}\).
  \item Normal approximation works when \(np\) and \(n(1-p)\) are not too small.
\end{itemize}
\end{corebox}

\begin{recallbox}
\begin{enumerate}
  \item Define \(\hat p\) and its approximate SE.
  \item When is the Normal approximation to the Binomial reasonable?
  \item Give a real example where a proportion is the right summary.
\end{enumerate}
\end{recallbox}

\begin{practicebox}
From 250 patients, 37 show a side effect. Compute \(\hat p\) and an approximate 95\% CI.
\end{practicebox}

\begin{rbox}
\begin{lstlisting}[language=R]
x <- 37; n <- 250
phat <- x/n
se <- sqrt(phat*(1-phat)/n)
ci <- phat + c(-1,1)*qnorm(0.975)*se
phat; ci
\end{lstlisting}
\end{rbox}

\reviewticks

% =========================================================
\section{One-Sample Proportion: Confidence Interval and Test}

\begin{corebox}
\begin{itemize}
  \item CI for \(p\): \texttt{prop.test(x, n)} gives an approximate (Wilson-like) CI; \texttt{binom.test} gives an exact CI.
  \item Hypothesis test for \(p\) with null \(p_0\): z (approximate) or exact binomial test.
  \item Report both \(\hat p\) and the CI; p-value addresses compatibility with \(H_0\).
\end{itemize}
\end{corebox}

\begin{recallbox}
\begin{enumerate}
  \item Which R function gives an exact binomial test and CI?
  \item In words, what does a small p-value tell you about \(H_0\)?
  \item Why can an exact method be preferable with small \(n\)?
\end{enumerate}
\end{recallbox}

\begin{practicebox}
Test whether the true adverse-event rate differs from 10\% when \(x=37, n=250\).
\end{practicebox}

\begin{rbox}
\begin{lstlisting}[language=R]
binom.test(37, 250, p = 0.10)
prop.test(37, 250, p = 0.10, correct = TRUE)
\end{lstlisting}
\end{rbox}

\reviewticks

% =========================================================
\section{Two Proportions: Difference, CI, and Test}

\begin{corebox}
\begin{itemize}
  \item Compare \(p_1 - p_2\) with a two-sample test for proportions; use \texttt{prop.test(x = c(x1,x2), n = c(n1,n2))}.
  \item Report the CI for \(p_1 - p_2\) and interpret direction and magnitude.
  \item Avoid over-interpreting p-values without effect-size context.
\end{itemize}
\end{corebox}

\begin{recallbox}
\begin{enumerate}
  \item Write the parameter of interest for two proportions.
  \item Name one assumption that justifies the Normal approximation here.
  \item What does it mean if 0 is inside the CI for \(p_1 - p_2\)?
\end{enumerate}
\end{recallbox}

\begin{practicebox}
Group A: 18/120 successes; Group B: 29/150. Test for a difference and give the 95\% CI.
\end{practicebox}

\begin{rbox}
\begin{lstlisting}[language=R]
prop.test(x = c(18,29), n = c(120,150))
\end{lstlisting}
\end{rbox}

\reviewticks

% =========================================================
\section{Association in 2x2 Tables: Risk Difference, Risk Ratio, Odds Ratio}

\begin{corebox}
\begin{itemize}
  \item Risk difference (RD): \(p_1 - p_2\). Risk ratio (RR): \(p_1/p_2\). Odds ratio (OR): \(\frac{p_1/(1-p_1)}{p_2/(1-p_2)}\).
  \item Interpretation depends on design (cohort vs case-control). OR approximates RR when outcomes are rare.
  \item Always report context and time frame.
\end{itemize}
\end{corebox}

\begin{recallbox}
\begin{enumerate}
  \item Define RD, RR, and OR.
  \item When is OR approximately equal to RR?
  \item Give one pitfall when interpreting ratios.
\end{enumerate}
\end{recallbox}

\begin{practicebox}
From a 2x2 table, compute RD, RR, and OR. Which is most interpretable for patients in your context?
\end{practicebox}

\begin{rbox}
\begin{lstlisting}[language=R]
# Suppose tab is matrix(c(a,b,c,d), nrow=2, byrow=TRUE)
prop <- prop.table(tab, 1)
p1 <- prop[1,2]; p2 <- prop[2,2]
RD <- p1 - p2
RR <- p1 / p2
OR <- (p1/(1-p1)) / (p2/(1-p2))
c(RD=RD, RR=RR, OR=OR)
\end{lstlisting}
\end{rbox}

\reviewticks

% =========================================================
\section{Study Design: Experiments vs Observational, Bias and Confounding}

\begin{corebox}
\begin{itemize}
  \item Randomisation, control, and blinding reduce bias; observational studies are vulnerable to confounding.
  \item Always state the unit of analysis, sampling frame, and inclusion or exclusion criteria.
  \item Association is not causation; consider DAG-like thinking to name potential confounders.
\end{itemize}
\end{corebox}

\begin{recallbox}
\begin{enumerate}
  \item One difference between experimental and observational designs.
  \item Define confounding in one sentence.
  \item Name two common sources of bias.
\end{enumerate}
\end{recallbox}

\begin{practicebox}
Take a claim from news or social media. Identify whether the underlying study is experimental or observational and list likely confounders.
\end{practicebox}

\begin{rbox}
\begin{lstlisting}[language=R]
# Simple random sample indices
i <- sample.int(nrow(D), size = 100)
D_s <- D[i,]
\end{lstlisting}
\end{rbox}

\reviewticks

% =========================================================
\section{Errors, Power, and Planning}

\begin{corebox}
\begin{itemize}
  \item Type I error (false positive) rate is set by \(\alpha\); Type II error relates to \(1 - \)power.
  \item Power increases with larger effects, larger \(n\), smaller variability, and higher \(\alpha\) (trade-offs apply).
  \item Pre-specify hypotheses and primary outcomes to avoid p-hacking.
\end{itemize}
\end{corebox}

\begin{recallbox}
\begin{enumerate}
  \item Define power in words.
  \item Name two knobs that increase power (holding others fixed).
  \item Why is multiple testing dangerous without correction?
\end{enumerate}
\end{recallbox}

\begin{practicebox}
Sketch how the required \(n\) changes when the target effect size halves (qualitatively). What happens to power if \(n\) stays fixed?
\end{practicebox}

\begin{rbox}
\begin{lstlisting}[language=R]
# Crude simulation of power for a one-sample t under mean shift
delta <- 0.3; n <- 40; B <- 1000
pvals <- replicate(B, t.test(rnorm(n, mean=delta, sd=1))$p.value)
mean(pvals < 0.05)  # approximate power
\end{lstlisting}
\end{rbox}

\reviewticks

% =========================================================
\section{Correlation (Pearson r) and Scatterplots}

\begin{corebox}
\begin{itemize}
  \item Pearson r measures linear association (from -1 to 1); it is unitless and symmetric in x and y.
  \item Nonlinear patterns can yield r near 0 even when variables are strongly related.
  \item Outliers can distort r; always inspect the scatterplot.
\end{itemize}
\end{corebox}

\begin{recallbox}
\begin{enumerate}
  \item What does the sign and magnitude of r indicate?
  \item Why must you always look at the scatterplot before trusting r?
  \item Give one situation where r is inappropriate.
\end{enumerate}
\end{recallbox}

\begin{practicebox}
Compute r between two quantitative variables and draw the scatterplot. Describe form, strength, and outliers.
\end{practicebox}

\begin{rbox}
\begin{lstlisting}[language=R]
plot(D$x, D$y)
cor(D$x, D$y)
cor.test(D$x, D$y)
\end{lstlisting}
\end{rbox}

\reviewticks

% =========================================================
\section{Transformations and Nonlinearity}

\begin{corebox}
\begin{itemize}
  \item Log or square-root transforms can stabilise variance and linearise relationships.
  \item Interpret coefficients on the transformed scale carefully (for example, log-y implies multiplicative effects).
  \item Compare residual plots before and after transformation.
\end{itemize}
\end{corebox}

\begin{recallbox}
\begin{enumerate}
  \item Name one reason to take logs of y.
  \item After logging y, how would you interpret a slope of 0.07?
  \item What visual cue in residuals-versus-fitted suggests a variance problem?
\end{enumerate}
\end{recallbox}

\begin{practicebox}
Fit models with y and with log(y); compare residual diagnostics and R output.
\end{practicebox}

\begin{rbox}
\begin{lstlisting}[language=R]
m1 <- lm(y ~ x, data=D)
m2 <- lm(log(y) ~ x, data=D)
par(mfrow=c(1,2))
plot(fitted(m1), rstudent(m1)); abline(h=0)
plot(fitted(m2), rstudent(m2)); abline(h=0)
par(mfrow=c(1,1))
\end{lstlisting}
\end{rbox}

\reviewticks

% =========================================================
\section{Outliers, Leverage, and Influence}

\begin{corebox}
\begin{itemize}
  \item Leverage points have unusual x; influential points change fit noticeably (for example, large Cook distance).
  \item Check hat values and Cook distance; diagnose, then justify any exclusions transparently.
  \item Refit with and without suspicious points and compare conclusions.
\end{itemize}
\end{corebox}

\begin{recallbox}
\begin{enumerate}
  \item Distinguish leverage and influence.
  \item Name two diagnostics for influence.
  \item Why is pre-specifying exclusion rules important?
\end{enumerate}
\end{recallbox}

\begin{practicebox}
Identify the top three most influential observations in your regression and inspect their raw records.
\end{practicebox}

\begin{rbox}
\begin{lstlisting}[language=R]
fit <- lm(y ~ x, data=D)
h <- hatvalues(fit)
cd <- cooks.distance(fit)
head(sort(cd, decreasing=TRUE), 3)
\end{lstlisting}
\end{rbox}

\reviewticks

% =========================================================
\section{Prediction and Intervals in Regression}

\begin{corebox}
\begin{itemize}
  \item Use \texttt{predict(..., interval="confidence")} for mean response; use \texttt{interval="prediction"} for a new individual.
  \item Prediction intervals are wider than confidence intervals.
  \item Do not extrapolate far beyond observed x.
\end{itemize}
\end{corebox}

\begin{recallbox}
\begin{enumerate}
  \item Difference between a confidence interval for the mean response and a prediction interval.
  \item Why are prediction intervals wider?
  \item What is extrapolation and why is it risky?
\end{enumerate}
\end{recallbox}

\begin{practicebox}
Fit an SLR and compute both CI and PI at x values near the center of your data. Compare widths.
\end{practicebox}

\begin{rbox}
\begin{lstlisting}[language=R]
fit <- lm(y ~ x, data=D)
new <- data.frame(x = c(10, 20))
conf <- predict(fit, new, interval = "confidence")
pred <- predict(fit, new, interval = "prediction")
conf; pred
\end{lstlisting}
\end{rbox}

\reviewticks

% =========================================================
\section{ANOVA (Concept) and Categorical Predictors}

\begin{corebox}
\begin{itemize}
  \item One-way ANOVA tests equality of k group means; equivalent to regression with k-1 dummy variables.
  \item Assumptions mirror SLR errors: independence, Normality within groups, equal variances.
  \item Report group means with CIs and the overall F test; follow up with planned contrasts where relevant.
\end{itemize}
\end{corebox}

\begin{recallbox}
\begin{enumerate}
  \item What does one-way ANOVA test?
  \item Name the error assumptions for ANOVA.
  \item How do you represent a 4-level factor in regression?
\end{enumerate}
\end{recallbox}

\begin{practicebox}
Run one-way ANOVA for y across a 3-level factor and show group means with 95\% CIs.
\end{practicebox}

\begin{rbox}
\begin{lstlisting}[language=R]
fit <- aov(y ~ group, data=D)
summary(fit)
aggregate(y ~ group, data=D, FUN=mean)
T <- TukeyHSD(fit)
T
\end{lstlisting}
\end{rbox}

\reviewticks

% =========================================================
\section*{Fast Review Sheet (pin on your wall)}
\addcontentsline{toc}{section}{Fast Review Sheet}

\begin{tcolorbox}[colback=SoftBg,colframe=Accent!40!black,breakable,boxrule=0.5pt,arc=2mm]
\begin{itemize}
  \item \textbf{Probability and tables:} marginal / joint / conditional; independence check: \( \Pr(A\mid B) \stackrel{?}{=} \Pr(A) \). For 2x2, also report \textbf{RD}, \textbf{RR}, \textbf{OR} (when events are rare, \(\mathrm{OR} \approx \mathrm{RR}\)).
  \item \textbf{Sampling and CLT:} the sampling distribution of \(\bar y\) is approximately Normal for large \(n\); \(\mathrm{SE}(\bar y) = s/\sqrt{n}\).
  \item \textbf{CIs and SEs:} width increases with conf.level or \(s\); width decreases with \(n\). For a proportion \(\hat p\): \(\mathrm{SE}(\hat p) \approx \sqrt{\hat p(1-\hat p)/n}\).
  \item \textbf{Means:} one-sample \(t\) for a mean; \textbf{Welch two-sample \(t\)} for independent groups; \textbf{paired \(t\)} on differences for within-subject designs. Always report estimate, CI, and a one-sentence practical interpretation.
  \item \textbf{SLR:} model \(y = \beta_0 + \beta_1 x + \varepsilon\). Interpret \(\beta_1\) as change in \(y\) per 1-unit increase in \(x\); \(\beta_0\) may be non-sensical if \(x=0\) is outside the data. Check \textbf{LINE}; inspect residuals, leverage, and Cook distance.
  \item \textbf{Prediction vs confidence:} \verb|predict(..., interval="confidence")| is for the mean response; \verb|interval="prediction"| is for a new individual (wider).
  \item \textbf{Power and planning:} power increases with larger effects, larger \(n\), smaller variability, and higher \(\alpha\) (trade-offs). Pre-specify outcomes; avoid p-hacking.
  \item \textbf{Minimal R verbs to remember:} \verb|t.test(...)|; \verb|prop.test(...)| / \verb|binom.test(...)|; \verb|table| and \verb|prop.table|; \verb|lm(y~x)|; \verb|plot(fitted(), rstudent())|; \verb|predict(..., interval=)|.
\end{itemize}
\end{tcolorbox}

\section*{How to schedule your catch-up (suggested)}
\addcontentsline{toc}{section}{How to schedule your catch-up}

\begin{tcolorbox}[colback=SoftBg,colframe=Accent!40!black,breakable,boxrule=0.5pt,arc=2mm]
\begin{itemize}
  \item \textbf{Week 1 (catch-up):} two lectures per day (about 35--45 min each).
  \begin{itemize}
    \item For each lecture: 6 min Core skim $\rightarrow$ 5 min Active Recall (eyes off) $\rightarrow$ 8--10 min Micro Practice $\rightarrow$ 5--8 min R Mini-Kit.
    \item End of day: 15 min mixed recall (pick 6--8 questions across the day's lectures).
  \end{itemize}
  \item \textbf{Week 2 (consolidate):} revisit each lecture on Day 2 and Day 7; do only Active Recall plus one Micro Practice. Tick the review boxes: Day 0 / 2 / 7 / 14.
  \item \textbf{Error log protocol:} when you miss an item, write the reason and a fix in a one-page sheet you see daily.
  \item \textbf{R reps:} once per day, retype one Mini-Kit from memory (no copy-paste) to keep commands fluent.
  \item \textbf{Exam warm-up:} 3 blocks $\times$ 30 MCQs under time; after each block, classify errors (concept vs slip) and fix with one targeted Micro Practice.
\end{itemize}
\end{tcolorbox}

\end{document}
